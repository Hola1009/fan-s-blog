> [!question] 单节点 redis 存在的问题
> - 数据丢失: redis 是内存存储, 服务重启可能导致数据丢失
> - 并发能力: 单节点无法应对 618 这样的高并发场景
> - 故障恢复: 如果 redis 宕机则服务不可用了, 如存储的用户 session
> - 存储能力: Redis 基于内存, 单节点能存储的数据量难以满足海量数据需求

基于上述问题我们需要实现
- redis 数据持久化
- 搭建主从集群, 实现读写分离
- 利用 redis 哨兵, 实现健康检测和自动恢复 
- 搭建分片集群, 利用插槽机制实现动态扩容

## Redis 持久化
### RDB
RDB全称Redis Database Backup file（Redis数据备份文件），也被叫做Redis数据快照。简单来说就是把内存中的所有数据都记录到磁盘中。当Redis实例故障重启后，从磁盘读取快照文件，恢复数据。

快照文件称为RDB文件，默认是保存在当前运行目录。
```bash
save # 由 redis 主线程来执行 RDB, 会阻塞所有指令
```

> [!tip]
> 默认在安全停机时执行持久化指令

#### 配置文件
Redis内部有触发RDB的机制，可以在redis.conf文件中找到，格式如下：
```bash
save 900 1 # 900 内至少有 1 key 被修改, 则执行 bgsave
```

> [!tip]
> 如果 `sava ""` 标识禁用 RDB

RDB的其它配置也可以在redis.conf文件中设置：
```bash
# 是否压缩 ,建议不开启，压缩也会消耗cpu，磁盘的话不值钱
rdbcompression yes

# RDB文件名称
dbfilename dump.rdb 

# 文件保存的路径目录
dir ./
```

#### fork 过程
bgsave开始时会fork主进程得到子进程，子进程共享主进程的内存数据。完成fork后读取内存数据并写入 RDB 文件.

进程不能直接操作物理内存, frok 的过程不是对内存数据做拷贝而是拷贝页表给子进程, 这样子线程就可以直接通过拷贝来的页表去读取内存数据了, 读取的是否为了防止不一致性, 将禁止写操作, 任何写都将发生在副本数据上, 以后的读操作也将映射到副本上, 就是代替了原来的数据
![[Pasted image 20241120230946.png|600]]

> [!tip] 页表
> 虚拟内存与物理内存之间的映射关系

#### summary
RDB方式bgsave的基本流程？
- fork主进程得到一个子进程，共享内存空间
- 子进程读取内存数据并写入新的RDB文件
- 用新RDB文件替换旧的RDB文件。
RDB会在什么时候执行？save 60 1000代表什么含义？
- 默认是服务停止时。
- 代表60秒内至少执行1000次修改则触发RDB
RDB的缺点？
- RDB执行间隔时间长，两次RDB之间写入数据有丢失的风险 (持久化的过是比较耗时的所以不能将间隔实现调太短)
- fork子进程、压缩、写出RDB文件都比较耗时

### AOP 持久化
AOF全称为Append Only File（追加文件）。Redis处理的每一个写命令都会记录在AOF文件，可以看做是命令日志文件。
![[Pasted image 20241120231953.png|500]]
#### 配置文件
AOF默认是关闭的，需要修改redis.conf配置文件来开启AOF：
```bash
# 是否开启AOF功能，默认是no
appendonly yes

# AOF文件的名称
appendfilename "appendonly.aof"
```

AOF的命令记录的频率也可以通过redis.conf文件来配：
```bash
# 表示每执行一次写命令，立即记录到AOF文件
appendfsync always

# 写命令执行完先放入AOF缓冲区，然后表示每隔1秒将缓冲区数据写到AOF文件，是默认方案
appendfsync everysec

# 写命令执行完先放入AOF缓冲区，由操作系统决定何时将缓冲区内容写回磁盘
appendfsync no
```

![[Pasted image 20241120232754.png]]

Redis也会在触发阈值时自动去重写AOF文件。阈值也可以在redis.conf中配置：
```bash
# AOF文件比上次文件 增长超过多少百分比则触发重写  
auto-aof-rewrite-percentage 100  
# AOF文件体积最小多大以上才触发重写  
auto-aof-rewrite-min-size 64mb
```

#### 解决无效操作问题
只要写是写操作 aop 就会记录, 如果对一个值进行对此赋值操作, 那么最后一次操作之前都是无效操作, 存储这些操作将加大内存的占用
通过执行 bgrewriteaof 命令, 可以让 aop 文件执行重写功能, 用最少的命令达到相同的效果

![[Pasted image 20241121183258.png]]

### summary
RDB和AOF各有自己的优缺点，如果对数据安全性要求较高，在实际开发中往往会结合两者来使用。

![[Pasted image 20241121184202.png]]

## Redis 主从
### 搭建主从架构
单节点 Redis 的并发能力是有上限的, 要进一步提高 Redis 的并发能力, 就需要搭建主从集群, 实现读写分离, 提高读的能力
![[Pasted image 20241121185007.png|700]]
#### 准备
1. 创建 3 个文件夹用来存放 3 份不同的配置文件和目录
2. 将配置文件拷贝到每个实例目录
3. 修改每个实例端口, 工作目录
4. 修改每个实例的声明 ip

#### 开启主从关系
- 修改配置文件 (永久)
	- 在 redis.conf 添加一行配置  `slaveof <masterip> <masterport>`
- 使用 redis-cli 客户端执行 `slaveof <masterip> <masterport>` 重启后生效

### 主从同步原理
#### 全量同步
主从第一次同步是 `全量同步` , 主执行 bgsave 生成 rdb 然后将 rdb 发给 slave, 在 RDB 期间所执行的指令会被保存到 repl_baklog 文件中, 执行完 RDB 之后, 会将 repl_bcklog 发送给 slave, 然后 slave 再执行这些指令 
![[Pasted image 20241121192309.png]]
这样做比较消耗性能

#### 如何判断 slave 是不是第一次来同步数据
这里会用到两个很重要的概念：
- Replication Id：简称replid，是数据集的标记，id一致则说明是同一数据集。每一个master都有唯一的replid，slave则会继承master节点的replid
- offset：偏移量，随着记录在repl_baklog中的数据增多而逐渐增大。slave完成同步时也会记录当前同步的offset。如果slave的offset小于master的offset，说明slave数据落后于master，需要更新。
因此slave做数据同步，必须向master声明自己的replication id 和offset，master才可以判断到底需要同步哪些数据

通过判断 replid 和 offest 来判断

> [!question] 简述全量同步的流程
> - slave节点请求增量同步- master节点判断replid，发现不一致，拒绝增量同步
> - master将完整内存数据生成RDB，发送RDB到slave
> - slave清空本地数据，加载master的RDB
> - master将RDB期间的命令记录在repl_baklog，并持续将log中的命令发送给slave
> - slave执行接收到的命令，保持与master之间的同步
> 

#### 增量同步
主从第一次同步是全量同步，但如果slave重启后同步，则执行增量同步
![[Pasted image 20241121195400.png]]
这个圈既是 repl_baklog 的大小上限, 如果通过对 offset 计算, 得出未备份的数据, 超过了这个大小, 就会执行全量同步, 因为以前一部分未备份的数据被覆盖了

repl_baklog大小有上限，写满后会覆盖最早的数据。如果slave断开时间过久，导致尚未备份的数据被覆盖，则无法基于log做增量同步，只能再次全量同步。

#### 主从同步优化
主要点就是减少全量同步和提高全量同步的效率
- 在master中配置 repl-diskless-sync yes `启用无磁盘复制`，避免全量同步时的磁盘 IO。(之前的逻辑是先将RDB写入磁盘再发给 slave, 现在取消同步到磁盘的过程, 直接发给 slave)
- 空值 Redis 单节点的内存上限，减少 RDB 导致的过多磁盘 IO
- `适当提高 repl_baklog 的大小`，发现 slave 宕机时尽快实现故障恢复，尽可能避免全量同步
- `限制一个 master上的 slave 节点数量`，如果实在是太多 slave，则可以采用主-从-从链式结构，减少 master 压力 

#### summary
简述全量同步和增量同步区别？
- 全量同步：master 将完整内存数据生成 RDB，发送 RDB 到 slave。后续命令则记录在 repl_baklog，逐个发送给 slave。
- 增量同步：slave 提交自己的 offset 到 master，master 获取 repl_baklog 中从 offset 之后的命令给 slave

什么时候执行全量同步？
- slave 节点第一次连接 master 节点时
- slave 节点断开时间太久，repl_baklog 中的 offset 已经被覆盖时

什么时候执行增量同步？
- slave 节点断开又恢复，并且在 repl_baklog 中能找到 offset 时

## 哨兵
> [!question]
> 如果 slave 宕机了, 恢复后可以直接找到 master 来同步数据, 但是 master 宕机了该怎么办呢?

如果做了持久化那还好, 对于恢复数据来说那没什么大问题, 但是在 master 宕机期间, 不能进行读操作, 只能进行读操作, 可用性大大降低了

### 哨兵的作用和工作原理
Redis 提供了烧饼i (Sentinel) 机制来实现主从集权的自动故障恢复. 哨兵的结果和作用如下
- `监控`: Sentinel 会不断检查您的 master 和 slave 是否按照预期工作
- `自动故障恢复`: 如果 master 故障, Sentinel 会将一个 slave 提升为 master. 当故障实例恢复后也要以新的 master 为主 
- `通知`: *Sentinel 充当 Redis 客户端的服务发现来源*, 当集群发生故障转移时, 会将最新消息推送给 Redis 端

#### 服务状态监控
Sentinel 基于心跳机制检测服务状态, 每隔 1 秒向集群的每个实例发送 ping 命令
- `主观下线`: 如果某 sentinel 节点发现某实例未在规定实践响应, 则认为该实例 `主观下线`
- 客观下线: 若超过指定数量( quorum )的 sentinel 都认为该实例主观下线, 则该实例客观下线. quorum 值最好是超过 sentinel 实例数量的一半

#### 选举新的 master
一旦发现master故障，sentinel 需要在 salve 中选择一个作为新的 master，选择依据如下
- 首先会判断slave节点与master节点断开时间长短，如果超过指定值（down-after-milliseconds * 10）则会排除该slave节点
- 然后判断slave节点的slave-priority值，越小优先级越高，如果是0则永不参与选举
- 如果slave-prority一样，则判断slave节点的offset值，越大说明数据越新，优先级越高
- 最后是判断slave节点的运行id大小，越小优先级越高。

#### 如何实现故障转移
当选中了其中一个 slave 为新的 master 后 , 故障的转移的步骤如下
- sentinel 给备选的 slave1 节点发送 `slaveof no one` 命令, 该节点称为 master
- sentinel 给所有其他 slave 发送 `slaveof <newMasterIp> <newMasterPort>` , 让 slave 成为新的 master 的从节点, 开始从新的 master 上同步数据
- 最后, sentinel 将故障节点标记为 slave , 当故障节点恢复后会从新的 master 获取同步数据, 并称为新 master 的 slave

#### summary
Sentinel的三个作用是什么？
- 监控
- 故障转移
- 通知

Sentinel如何判断一个redis实例是否健康？
- 每隔1秒发送一次ping命令，如果超过一定时间没有相向则认为是主观下线
- 如果大多数sentinel都认为实例主观下线，则判定服务下线

故障转移步骤有哪些？
- 首先选定一个slave作为新的master，执行slaveof no one
- 然后让所有节点都执行slaveof 新master
- 修改故障节点，执行slaveof 新master

### 搭建哨兵集群
![[Pasted image 20241122063046.png|400]]

1. 分配 3 个端口来运行 3 个 sentinel 实例
2. 准备 3 个文件夹来存放配置文件

### RedisTemplate 的哨兵模式
在 sentinel 集群监管下的 redis 主从集群, 其节点会应为自动故障转移而发生变化, Redis 客户都安必须感知这种变化, 即时更新连接信息. Spring 的 RedisTemplate 底层利用 lettcue 实现了节点的感知和自动切换

1. 在pom文件中引入redis的starter依赖
2. 然后在配置文件中指定 sentinel 相关信息
```yml
spring:  
  redis:  
  sentinel:  
  master: mymaster # 指定master名称  
  nodes: # 指定redis-sentinel集群信息   
	- 192.168.150.101:27001  
    - 192.168.150.101:27002  
    - 192.168.150.101:27003  

```

3. 配置主从读写分离
```java
@Bean  
public LettuceClientConfigurationBuilderCustomizer configurationBuilderCustomizer(){  
    return configBuilder -> configBuilder.readFrom(ReadFrom.REPLICA_PREFERRED);  
}
```

这里的 ReadFrom 是配置 Redis 的读取策略，是一个枚举，包括下面选择：
- MASTER：从主节点读取
- MASTER_PREFERRED：优先从 master 节点读取，master 不可用才读取 replica
- REPLICA：从 slave（replica）节点读取
- REPLICA\_PREFERRED：优先从slave（replica）节点读取，所有的 slave 都不可用才读取 master

## Redis 分片集群
- 搭建分片集群
- 散列插槽
- 集群伸缩
- 故障转移
- RedisTemplate 访问分片集群

### 分片集群结构
主从和哨兵可以解决高可用、高并发读的问题。但是依然有两个问题没有解决：
- 海量数据存储问题
- 高并发写的问题

使用分片集群可以解决上述问题，分片集群特征：
- 集群中有多个master，每个master保存不同数据
- 每个master都可以有多个slave节点
- master之间通过ping监测彼此健康状态
- 客户端请求可以访问集群任意节点，最终都会被转发到正确节点

### 搭建分片集群
 1. 创建出多个目录, 并复制配置文件
 2. 创建集群

### 散列插槽










