## 雪崩问题
小问题引发大事故
微服务调用链路中的某个服务故障，引起整个链路中的所有微服务都不可用，这就是雪崩。

雪崩问题产生的原因是什么？
- 微服务相互调用，服务提供者出现故障或阻塞。
- 服务调用者没有做好异常处理，导致自身故障。
- 调用链中的所有服务级联失败，导致整个集群故障

解决问题的思路有哪些？
- 尽量避免服务出现故障或阻塞。
	- 保证代码的健壮性；
	- 保证网络畅通；
	- 能应对较高的并发请求；
- 服务调用者做好远程调用异常的后备方案，避免故障扩散
## 服务保护方案
### 请求限流
请求限流: 限制访问微服务的请求的并发量, 避免服务因流量激增出现故障
![[Pasted image 20240603165527.png]]

![[Pasted image 20240603165539.png]]

### 线程隔离
线程隔离：也叫做 ==舱壁模式== ，模拟船舱隔板的防水原理。通过==限定每个业务能使用的线程数量==而将故障业务隔离，避免故障扩散

![[Pasted image 20240603165918.png]]

固定可以使用的线程的个数, 就算出现故障, 也不会把资源耗尽

### 服务熔断
服务熔断：由断路器统计请求的异常比例或慢调用比例，如果超出阈值则会熔断该业务，则拦截该接口的请求。
熔断期间，所有请求快速失败，全都走fallback(备选方案/兜底方案)逻辑。

![[Pasted image 20240603170247.png|600]]

> [!summary] 总结
> 解决雪崩问题的常见方案有哪些？
•请求限流：限制流量在服务可以处理的范围，避免因突发流量而故障
•线程隔离：控制业务可用的线程数量，将故障隔离在一定范围
•服务熔断：将异常比例过高的接口断开，拒绝所有请求，直接走fallback
•失败处理：定义fallback逻辑，让业务失败时不再抛出异常，而是返回默认数据或友好提示

### 服务保护技术
![[Pasted image 20240603170837.png]]

## Sentinel
Sentinel是阿里巴巴开源的一款微服务流量控制组件。官网地址： [https://sentinelguard.io/zh-cn/index.html](https://sentinelguard.io/zh-cn/index.html)
![[Pasted image 20240603171334.png]]

安装 Sentinel
导入jar包
然后在对应目录下运行如下指令
```Shell
java -Dserver.port=8090 -Dcsp.sentinel.dashboard.server=localhost:8090 -Dproject.name=sentinel-dashboard -jar sentinel-dashboard.jar
```

密码和用户名 都是 sentinel


### 微服务整合 Sentinel
```XML
<!--sentinel-->
<dependency>
    <groupId>com.alibaba.cloud</groupId> 
    <artifactId>spring-cloud-starter-alibaba-sentinel</artifactId>
</dependency>
```

```YAML
spring:
  cloud: 
    sentinel:
      transport:
        dashboard: localhost:8090
```


#### 簇点链路
簇点链路，就是 **单机调用链路** 。是一次请求进入服务后经过的每一个被Sentinel监控的资源链。默认Sentinel会监控SpringMVC的每一个Endpoint（http接口/controller接口）。限流、熔断等都是针对簇点链路中的资源设置的。而资源名默认就是接口的请求路径

![[Pasted image 20240606104452.png]]

Restful风格的API请求路径一般都相同，这会导致簇点资源名称重复。因此我们要修改配置，把请求方式+请求路径作为簇点资源名称：

```yml
sentinel:
  http-method-specify: true
```

#### 请求限流
点击流控按钮
限制每秒访问次数
![[Pasted image 20240606105419.png|600]]

#### 线程隔离
当商品服务出现阻塞或故障时，调用商品服务的购物车服务可能因此而被拖慢，甚至资源耗尽。所以必须限制购物车服务中查询商品这个业务的可用线程数，实现线程隔离。

因为一个业务卡住, 导致等待的线程数不断增加, 其他业务也会被卡住
![[Pasted image 20240606120530.png]]

给每个业务定额的线程数, 这样就算卡住也不会占用其他业务的资源了
![[Pasted image 20240606121011.png]]

```yml
server:  
  tomcat:  
    threads:  
      max: 50  # 设置最大线程数
    accept-count: 50  # 设置等待线程数
```

#### Fallbock(用户友好)
1. 将 FeignClient 作为 Sentinel 的簇点资源
```yml
feign:
  sentinel:  
    enabled: true
```

##### 给 FeignClient 编写 Fallback 逻辑
假如我们有一个FeignClient如下

```java
@FeignClient(value = "userservice)  
public interface UserClient {   
	@GetMapping("/user/{id}")    
	User findById(@PathVariable("id") Long id);  
}
```

步骤一:  自定义类, 实现FallbackFacory, 编写对某个FeignClient的fallback逻辑
```java
@Slf4j  
public class UserClientFallbackFactory implements FallbackFactory<UserClient> {    
	@Override    
	public UserClient create(Throwable throwable) {        
		// 创建UserClient接口实现类，实现其中的方法，编写失败降级的处理逻辑
		return new UserClient() {
					@Override
					public User findById(Long id) {                
						// 记录异常信息，可以返回空或抛出异常                
						log.error("查询用户失败", throwable);                
						return null;  
			}  
        };  
    }  
}
```

步骤二: 将刚刚定义的 UserClientFallbackFactory 注册成一个 bean

```java
@Bean  
public UserClientFallbackFactory userClientFallback(){    
	return new UserClientFallbackFactory();  
}
```

步骤三: 在UserClient接口中使用UserClientFallbackFactory
```java
@FeignClient(value = "userservice", fallbackFactory = UserClientFallbackFactory.class)  
public interface UserClient {    
	@GetMapping("/user/{id}")
	User findById(@PathVariable("id") Long id);  
}
```


#### 服务熔断
熔断是解决雪崩问题的重要手段。思路是由 **断路器** 统计服务调用的异常比例、慢请求比例，如果超出阈值则会熔断该服务。即拦截访问该服务的一切请求；而当服务恢复时，断路器会放行访问该服务的请求。

断绝故障服务, 避免资源浪费

open 表示 开启熔断
![[Pasted image 20240607132451.png]]

熔断规则
![[Pasted image 20240607133106.png]]

## 分布式事务

下单业务，前端请求首先进入订单服务，创建订单并写入数据库。然后订单服务调用购物车服务和库存服务：
- 购物车服务负责清理购物车信息
- 库存服务负责扣减商品库存
![[Pasted image 20240607134141.png]]

在分布式系统中，如果一个业务需要多个服务合作完成，而且每一个服务都有事务，多个事务必须同时成功或失败，这样的事务就是分布式事务。其中的每个服务的事务就是一个分支事务。整个业务称为全局事务。

### 初始Seata
Seata是 2019 年 1 月份蚂蚁金服和阿里巴巴共同开源的分布式事务解决方案。致力于提供高性能和简单易用的分布式事务服务，为用户打造一站式的分布式解决方案。

官网地址：[http://seata.io/](http://seata.io/)，其中的文档、播客中提供了大量的使用说明、源码分析。
![[Pasted image 20240607134912.png]]
之前 每个服务之间不知道彼此的执行状态, 解决分布式事务, 各个子事务之间必须能感知到彼此的事务状态, 才能保持状态一致
![[Pasted image 20240607135018.png]]

使用事务协调者让每个服务之间知道彼此的执行状态

#### Seata 架构
Seata事务管理中有三个重要的角色：
- TC (Transaction Coordinator) - 事务协调者：维护全局和分支事务的状态，协调全局事务提交或回滚。
- TM (Transaction Manager) - 事务管理器：定义全局事务的范围、开始全局事务、提交或回滚全局事务。
- RM (Resource Manager) - 资源管理器：管理分支事务，与TC交谈以注册分支事务和报告分支事务的状态
![[Pasted image 20240607135756.png]]

### 部署TC服务
TC 服务需要 记录和管理每个事务的信息, 所以为了安全考虑, 我们将这些信息存储在 数据库中

```Shell
docker run --name seata \
-p 8099:8099 \
-p 7099:7099 \
-e SEATA_IP=192.168.200.134 \
-v ./seata:/seata-server/resources \
--privileged=true \
--network hm-net \
-d \
seataio/seata-server:1.5.2
```

### 微服务集成Seata
首先引入 Seata 的依赖
```XML
<!--统一配置管理-->
  <dependency>
      <groupId>com.alibaba.cloud</groupId>
      <artifactId>spring-cloud-starter-alibaba-nacos-config</artifactId>
  </dependency>
  <!--读取bootstrap文件-->
  <dependency>
      <groupId>org.springframework.cloud</groupId>
      <artifactId>spring-cloud-starter-bootstrap</artifactId>
  </dependency>
  <!--seata-->
  <dependency>
      <groupId>com.alibaba.cloud</groupId>
      <artifactId>spring-cloud-starter-alibaba-seata</artifactId>
  </dependency>
```


```YAML
seata:
  registry: # TC服务注册中心的配置，微服务根据这些信息去注册中心获取tc服务地址
    type: nacos # 注册中心类型 nacos
    nacos:
      server-addr: 192.168.200.134:8848 # nacos地址
      namespace: "" # namespace，默认为空
      group: DEFAULT_GROUP # 分组，默认是DEFAULT_GROUP
      application: seata-server # seata服务名称
      username: nacos
      password: nacos
  tx-service-group: hmall # 事务组名称
  service:
    vgroup-mapping: # 事务组与tc集群的映射关系
      hmall: "default"
```

将其抽取成共享配置
![[Pasted image 20240607214734.png]]

然后去集成服务
bootstrap.yaml 文件
```yml
spring:  
  application:  
    name: cart-service  
  profiles:  
    active: dev  
  cloud:  
    nacos:  
      server-addr: 192.168.200.134:8848  
      config:  
        file-extension: yaml  
        shared-configs:  
          - data-id: shared-jdbc.yaml  
          - data-id: shared-log.yaml  
          - data-id: shared-swagger.yaml  
          - data-id: shared-seata.yaml
```

### XA模式
一阶段的工作：
- RM注册分支事务到TC
- RM执行分支业务sql但不提交
- RM报告执行状态到TC
二阶段的工作：
TC检测各分支事务执行状态
a.如果都成功，通知所有RM提交事务
b.如果有失败，通知所有RM回滚事务
•RM接收TC指令，提交或回滚事务

![[Pasted image 20240607231842.png]]

XA模式的优点是什么？
- 事务的强一致性，满足ACID原则。
- 常用数据库都支持，实现简单，并且没有代码侵入
XA模式的缺点是什么？
- 因为一阶段需要锁定数据库资源，等待二阶段结束才释放，性能较差
- 依赖关系型数据库实现事务

需要所有的服务全部执行完了, 才能提交事务

#### 实现XA模式
Seata的starter已经完成了XA模式的自动装配，实现非常简单，步骤如下：
1. 修改application.yml文件（每个参与事务的微服务），开启XA模式：
```yml
seata:  
  data-source-proxy-mode: XA # 开启数据源代理的XA模式
```
2. 给发起全局事务的入口方法添加@GlobalTransactional注解，本例中是OrderServiceImpl中的create方法：
```java
@Override  
@GlobalTransactional  
public Long createOrder(OrderFormDTO order) {    
	// 创建订单 ... 略  
    // 清理购物车 ...略
    // 扣减库存 ...略    return order.getId();  
}
```
### TA模式

Seata主推的是AT模式，AT模式同样是分阶段提交的事务模型，不过缺弥补了XA模型中资源锁定周期过长的缺陷。

经行数据操作后直接提交, 所以不能回滚, 但是在执行之前会对数据经行一个快照, 如果出错了, 就拿着快照将数据改回来

阶段一RM的工作：
- 注册分支事务
- 记录undo-log（数据快照）
- 执行业务sql并提交
- 报告事务状态
阶段二提交时RM的工作：
- 删除undo-log即可
阶段二回滚时RM的工作：
- 根据undo-log恢复数据到更新前

缺点: 会出现短暂的读不一致

![[Pasted image 20240607233606.png]]

#### 实现AT模式
首先，添加资料中的seata-at.sql到微服务对应的数据库中：
```sql
CREATE TABLE IF NOT EXISTS `undo_log`
(
    `branch_id`     BIGINT       NOT NULL COMMENT '分支事务id',
    `xid`           VARCHAR(128) NOT NULL COMMENT '全局事务id',
    `context`       VARCHAR(128) NOT NULL COMMENT 'undo_log context,such as serialization',
    `rollback_info` LONGBLOB     NOT NULL COMMENT 'rollback info',
    `log_status`    INT(11)      NOT NULL COMMENT '0:normal status,1:defense status',
    `log_created`   DATETIME(6)  NOT NULL COMMENT 'create datetime',
    `log_modified`  DATETIME(6)  NOT NULL COMMENT 'modify datetime',
    UNIQUE KEY `ux_undo_log` (`xid`, `branch_id`)
) ENGINE = InnoDB
  AUTO_INCREMENT = 1
  DEFAULT CHARSET = utf8mb4 COMMENT ='AT transaction mode undo table';
```

然后，修改application.yml文件，将事务模式修改为AT模式：

```yml
seata:
  data-source-proxy-mode: AT # 开启数据源代理的AT模式
```

### XA 和 TA 的区别
XA 强一致性
AT 最终一致性













